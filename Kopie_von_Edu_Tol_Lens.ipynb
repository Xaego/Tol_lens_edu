{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von Edu_Tol_Lens.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1OJMXC/3E4C2naIDXl6jK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xaego/Tol_lens_edu/blob/main/Kopie_von_Edu_Tol_Lens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0ldkqGrMthS",
        "outputId": "62697aba-a44c-4b07-c722-bc8e42488754"
      },
      "source": [
        "import scipy\n",
        "print(scipy.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sei6w-zry22R"
      },
      "source": [
        "# get all files\n",
        "import matplotlib.pyplot\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import fnmatch\n",
        "import io\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2jMweqNW5l9x"
      },
      "source": [
        "# google drive + colab\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwxgAIz6NTq"
      },
      "source": [
        "# Authentifizieren und erstellen Sie den PyDrive-Client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShYNk2ni6dTZ"
      },
      "source": [
        "# Textdatei erstellen und hochladen.\n",
        "uploaded = drive.CreateFile({'title': 'result.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiIX6UVl6m5R"
      },
      "source": [
        "# Laden Sie eine Datei nach ID und drucken Sie ihren Inhalt aus.\n",
        "downloaded = drive.CreateFile({'id': '1FFHiEKVYHWgN6UD4R55gceW7Q1tZ9v8Z'})\n",
        "\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentFile(\"result.txt\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax-cZylxzt07"
      },
      "source": [
        "def plot_horsepower(x, y):\n",
        "    plt.scatter(train_features['d2'], train_labels, label='Data')\n",
        "    plt.plot(x, y, color='k', label='Predictions')\n",
        "    plt.xlabel('d2')\n",
        "    plt.ylabel('rms')\n",
        "    plt.legend()\n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIPHThovzt5K"
      },
      "source": [
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        " \n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Do6YYwzt-L"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  # plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [rms]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7oDy0G_4imQ"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDcSSekPzuBi"
      },
      "source": [
        "full_path_txt = \"result.txt\"\n",
        "df = pd.read_csv(full_path_txt, sep=\" \", header=1, skiprows=0, encoding=\"UTF-16\", skipfooter=1, engine='python')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJV2cxb3zuE6"
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxMxE2cZtQT1"
      },
      "source": [
        "sns.pairplot(train_dataset[['rms', 'r1', 'd1', 'r2']], diag_kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ToQofrwag1"
      },
      "source": [
        "train_dataset.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e9S41Gdz3zU"
      },
      "source": [
        "split target value from the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RMd0Ujmz6XL"
      },
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('rms')\n",
        "test_labels = test_features.pop('rms')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_3Nd8pHz8mP"
      },
      "source": [
        "## Normalization ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBNE-Ev8z66T"
      },
      "source": [
        "print(train_dataset.describe().transpose()[['mean', 'std']])\n",
        "# Normalization layer\n",
        "normalizer = preprocessing.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "print(normalizer.mean.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBl5xiX9z62y"
      },
      "source": [
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "    print('First example:', first)\n",
        "    print('Normalized:', normalizer(first).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmlkkzuW0F_S"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiCamIFg0Fq_"
      },
      "source": [
        "# First create the horsepower Normalization layer:\n",
        "horsepower = np.array(train_features['r1'])\n",
        " \n",
        "horsepower_normalizer = preprocessing.Normalization(input_shape=[1,], axis=None)\n",
        "horsepower_normalizer.adapt(horsepower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXoh7briz6zq"
      },
      "source": [
        "# Build the sequential model:\n",
        "horsepower_model = tf.keras.Sequential([\n",
        "    horsepower_normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        " \n",
        "horsepower_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1h4oOmMz6vy"
      },
      "source": [
        "horsepower_model.predict(horsepower[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyu3bEjU0KxK"
      },
      "source": [
        "horsepower_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H264druC0KuD"
      },
      "source": [
        "%%time\n",
        "history = horsepower_model.fit(\n",
        "    train_features['r1'], train_labels,\n",
        "    epochs=100,\n",
        "    # suppress logging\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnGACvp10Kq6"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB54FYfA0Kny"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suvEkYjRxIY1"
      },
      "source": [
        "test_results = {}\n",
        "\n",
        "test_results['horsepower_model'] = horsepower_model.evaluate(\n",
        "    test_features['r1'],\n",
        "    test_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mSVGpo-65Ux"
      },
      "source": [
        "x = tf.linspace(95, 90, 10)\n",
        "#x = tf.linspace(95,96,200)\n",
        "y = horsepower_model.predict(x)\n",
        "plot_horsepower(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgq6pciHxjE-"
      },
      "source": [
        "# Multiple inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F34qfnaN65kQ"
      },
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBInLKC665nh"
      },
      "source": [
        "linear_model.predict(train_features[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruM5auae65qo"
      },
      "source": [
        "linear_model.layers[1].kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JiLRAZH65t5"
      },
      "source": [
        "linear_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31I4Iy0xxv7d"
      },
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features, train_labels, \n",
        "    epochs=100,\n",
        "    # suppress logging\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiF1ovXOKScL"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NU31tOgKS-8"
      },
      "source": [
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8SMi7om0eir"
      },
      "source": [
        "# A DNN regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjuDhaYFyFdV"
      },
      "source": [
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLYNSraYyMRF"
      },
      "source": [
        "One variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1_e056A65xS"
      },
      "source": [
        "dnn_horsepower_model = build_and_compile_model(horsepower_normalizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlS_iWNP0Kdj"
      },
      "source": [
        "dnn_horsepower_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzetNg-c0KZq"
      },
      "source": [
        "# Train the model:\n",
        "%%time\n",
        "history = dnn_horsepower_model.fit(\n",
        "    train_features['d2'], train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukCc-TQz0k4b"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-FRedl0k1M"
      },
      "source": [
        "x = tf.linspace(0.0, 250, 251)\n",
        "y = dnn_horsepower_model.predict(x)\n",
        "plot_horsepower(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsFHKWHy0kx6"
      },
      "source": [
        "test_results['dnn_horsepower_model'] = dnn_horsepower_model.evaluate(\n",
        "    test_features['d2'], test_labels,\n",
        "    verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OB8jPej0pUr"
      },
      "source": [
        "# Full model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqvcwwfT0kuy"
      },
      "source": [
        "dnn_model = build_and_compile_model(normalizer)\n",
        "dnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71v3q4et0kr6"
      },
      "source": [
        "%%time\n",
        "history = dnn_model.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)\n",
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKuBVWhC0kk7"
      },
      "source": [
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC20_g5c0ur6"
      },
      "source": [
        "# Performance #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQZQrZnf0tBb"
      },
      "source": [
        "pd.DataFrame(test_results, index=['Mean absolute error [rms]']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un6KEfxtysZk"
      },
      "source": [
        "make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWXT0Npq0s-C"
      },
      "source": [
        "test_predictions = dnn_model.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [rms]')\n",
        "plt.ylabel('Predictions [rms]')\n",
        "lims = [0, 1]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IluLVlj0s6q"
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins=25)\n",
        "plt.xlabel('Prediction Error [rms]')\n",
        "_ = plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD1_pH0y0syy"
      },
      "source": [
        "dnn_model.save('dnn_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK52HCBU0svb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}